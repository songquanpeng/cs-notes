<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>PyTorch 模型 | JustSong&#39;s CS Notes</title>
    <meta name="generator" content="VuePress 1.8.2">
    <script data-ad-client="ca-pub-4932639067711253" async="true" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <meta name="description" content="我的编程笔记">
    
    <link rel="preload" href="/assets/css/0.styles.7cfabf05.css" as="style"><link rel="preload" href="/assets/js/app.bf805b70.js" as="script"><link rel="preload" href="/assets/js/2.9b539265.js" as="script"><link rel="preload" href="/assets/js/11.c97887ff.js" as="script"><link rel="prefetch" href="/assets/js/10.294650a1.js"><link rel="prefetch" href="/assets/js/12.114bfd9d.js"><link rel="prefetch" href="/assets/js/13.6c58b81d.js"><link rel="prefetch" href="/assets/js/14.aefd1ad1.js"><link rel="prefetch" href="/assets/js/15.9d730a7f.js"><link rel="prefetch" href="/assets/js/16.17bd79dd.js"><link rel="prefetch" href="/assets/js/17.ee929e53.js"><link rel="prefetch" href="/assets/js/18.e998faa6.js"><link rel="prefetch" href="/assets/js/19.84d6215b.js"><link rel="prefetch" href="/assets/js/20.2ecae375.js"><link rel="prefetch" href="/assets/js/21.eba6645f.js"><link rel="prefetch" href="/assets/js/22.5cefd68c.js"><link rel="prefetch" href="/assets/js/23.65ea9669.js"><link rel="prefetch" href="/assets/js/24.67c70f73.js"><link rel="prefetch" href="/assets/js/25.12180319.js"><link rel="prefetch" href="/assets/js/26.39a67d11.js"><link rel="prefetch" href="/assets/js/27.5c665df0.js"><link rel="prefetch" href="/assets/js/28.431a8561.js"><link rel="prefetch" href="/assets/js/29.798cf88a.js"><link rel="prefetch" href="/assets/js/3.1f44eb07.js"><link rel="prefetch" href="/assets/js/30.33e4386c.js"><link rel="prefetch" href="/assets/js/31.4cbc6a38.js"><link rel="prefetch" href="/assets/js/32.2afb468b.js"><link rel="prefetch" href="/assets/js/33.4ade0428.js"><link rel="prefetch" href="/assets/js/34.bddc5ac2.js"><link rel="prefetch" href="/assets/js/35.7a2b9558.js"><link rel="prefetch" href="/assets/js/36.9047ebe9.js"><link rel="prefetch" href="/assets/js/37.e0756e28.js"><link rel="prefetch" href="/assets/js/38.86d35da4.js"><link rel="prefetch" href="/assets/js/39.aba07aa4.js"><link rel="prefetch" href="/assets/js/4.f2c31939.js"><link rel="prefetch" href="/assets/js/40.6ad44db8.js"><link rel="prefetch" href="/assets/js/41.43f963d9.js"><link rel="prefetch" href="/assets/js/42.5fde5b3a.js"><link rel="prefetch" href="/assets/js/43.b49aefde.js"><link rel="prefetch" href="/assets/js/44.4fb63ce5.js"><link rel="prefetch" href="/assets/js/45.e832a221.js"><link rel="prefetch" href="/assets/js/46.ff5b1caa.js"><link rel="prefetch" href="/assets/js/47.17a51250.js"><link rel="prefetch" href="/assets/js/5.9545ccdf.js"><link rel="prefetch" href="/assets/js/6.7fe74a9b.js"><link rel="prefetch" href="/assets/js/7.ac18156f.js"><link rel="prefetch" href="/assets/js/8.4ae70723.js"><link rel="prefetch" href="/assets/js/9.df7e8274.js">
    <link rel="stylesheet" href="/assets/css/0.styles.7cfabf05.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">JustSong's CS Notes</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  主页
</a></div><div class="nav-item"><a href="/languages/" class="nav-link">
  语言
</a></div><div class="nav-item"><a href="/frameworks/" class="nav-link router-link-active">
  框架
</a></div><div class="nav-item"><a href="/tools/" class="nav-link">
  工具
</a></div><div class="nav-item"><a href="/algorithms/" class="nav-link">
  算法
</a></div><div class="nav-item"><a href="/others/" class="nav-link">
  其他
</a></div> <a href="https://github.com/songquanpeng/cs-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  主页
</a></div><div class="nav-item"><a href="/languages/" class="nav-link">
  语言
</a></div><div class="nav-item"><a href="/frameworks/" class="nav-link router-link-active">
  框架
</a></div><div class="nav-item"><a href="/tools/" class="nav-link">
  工具
</a></div><div class="nav-item"><a href="/algorithms/" class="nav-link">
  算法
</a></div><div class="nav-item"><a href="/others/" class="nav-link">
  其他
</a></div> <a href="https://github.com/songquanpeng/cs-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Algorithms</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Frameworks</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/frameworks/" aria-current="page" class="sidebar-link">/frameworks/</a></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading open"><span>Py Torch</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/frameworks/PyTorch/" aria-current="page" class="sidebar-link">PyTorch 概述</a></li><li><a href="/frameworks/PyTorch/data.html" class="sidebar-link">PyTorch 数据处理</a></li><li><a href="/frameworks/PyTorch/model.html" aria-current="page" class="active sidebar-link">PyTorch 模型</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/model.html#模型的构建" class="sidebar-link">模型的构建</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/model.html#通过继承-nn-module-来进行构建" class="sidebar-link">通过继承 nn.module 来进行构建</a></li><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/model.html#使用-nn-sequelize-的构造函数来进行构建" class="sidebar-link">使用 nn.Sequelize 的构造函数来进行构建</a></li><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/model.html#使用-nn-sequential-的-add-module-来进行构建" class="sidebar-link">使用 nn.Sequential() 的 add_module 来进行构建</a></li><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/model.html#使用-nn-modulelist-来进行构建" class="sidebar-link">使用 nn.ModuleList() 来进行构建</a></li><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/model.html#查看模型结构" class="sidebar-link">查看模型结构</a></li></ul></li><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/model.html#模型的参数初始化" class="sidebar-link">模型的参数初始化</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/model.html#对于单个网络层" class="sidebar-link">对于单个网络层</a></li><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/model.html#对于-nn-module-包括-nn-sequential" class="sidebar-link">对于 nn.Module（包括 nn.Sequential）</a></li></ul></li><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/model.html#模型的评估" class="sidebar-link">模型的评估</a></li><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/model.html#模型的保存与加载" class="sidebar-link">模型的保存与加载</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/model.html#保存模型" class="sidebar-link">保存模型</a></li><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/model.html#加载模型" class="sidebar-link">加载模型</a></li></ul></li><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/model.html#参考" class="sidebar-link">参考</a></li></ul></li><li><a href="/frameworks/PyTorch/optimizer.html" class="sidebar-link">PyTorch 优化器</a></li><li><a href="/frameworks/PyTorch/tensor.html" class="sidebar-link">PyTorch Tensor</a></li><li><a href="/frameworks/PyTorch/torchvision.html" class="sidebar-link">torchversion 相关笔记</a></li></ul></section></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Languages</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Others</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Tools</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="pytorch-模型"><a href="#pytorch-模型" class="header-anchor">#</a> PyTorch 模型</h1> <h2 id="模型的构建"><a href="#模型的构建" class="header-anchor">#</a> 模型的构建</h2> <p>实际上模型层和模型没有本质区别，其对外提供的接口一致。</p> <h3 id="通过继承-nn-module-来进行构建"><a href="#通过继承-nn-module-来进行构建" class="header-anchor">#</a> 通过继承 <code>nn.module</code> 来进行构建</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">MyNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_feature<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>MyNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_feature<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> y

net <span class="token operator">=</span> MyNet<span class="token punctuation">(</span>num_feature<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
</code></pre></div><h3 id="使用-nn-sequelize-的构造函数来进行构建"><a href="#使用-nn-sequelize-的构造函数来进行构建" class="header-anchor">#</a> 使用 <code>nn.Sequelize</code> 的构造函数来进行构建</h3> <div class="language-python extra-class"><pre class="language-python"><code>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

<span class="token comment"># 使用列表：</span>
layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>InstanceNorm2d<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>layers<span class="token punctuation">)</span>

<span class="token comment"># 使用有序字典，可以指定网络层名字：</span>
<span class="token keyword">from</span> collections <span class="token keyword">import</span> OrderedDict
net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>OrderedDict<span class="token punctuation">(</span><span class="token punctuation">[</span>
          <span class="token punctuation">(</span><span class="token string">'linear'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token punctuation">(</span><span class="token string">'linear'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token punctuation">(</span><span class="token string">'linear'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="使用-nn-sequential-的-add-module-来进行构建"><a href="#使用-nn-sequential-的-add-module-来进行构建" class="header-anchor">#</a> 使用 <code>nn.Sequential()</code> 的 add_module 来进行构建</h3> <div class="language-python extra-class"><pre class="language-python"><code>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;relu1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;relu2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear3&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;sigmoid&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="使用-nn-modulelist-来进行构建"><a href="#使用-nn-modulelist-来进行构建" class="header-anchor">#</a> 使用 <code>nn.ModuleList()</code> 来进行构建</h3> <div class="language-python extra-class"><pre class="language-python"><code>self<span class="token punctuation">.</span>encode <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span>
self<span class="token punctuation">.</span>decode <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span>
self<span class="token punctuation">.</span>encode<span class="token punctuation">.</span>append<span class="token punctuation">(</span>ResBlk<span class="token punctuation">(</span>dim_in<span class="token punctuation">,</span> dim_out<span class="token punctuation">)</span><span class="token punctuation">)</span>
self<span class="token punctuation">.</span>decode<span class="token punctuation">.</span>insert<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> AdainResBlk<span class="token punctuation">(</span>dim_out<span class="token punctuation">,</span> dim_in<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>与 <code>nn.Sequelize</code> 的区别：<code>nn.Sequential</code> 是一个 module，其有 forward 函数，因此可以拿来直接输入。</p> <p><code>nn.ModuleList()</code> 相当于一个 Python 列表，但是其中的网络层参数可以被优化器发现和训练。</p> <h3 id="查看模型结构"><a href="#查看模型结构" class="header-anchor">#</a> 查看模型结构</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="模型的参数初始化"><a href="#模型的参数初始化" class="header-anchor">#</a> 模型的参数初始化</h2> <h3 id="对于单个网络层"><a href="#对于单个网络层" class="header-anchor">#</a> 对于单个网络层</h3> <h4 id="直接初始化为指定值"><a href="#直接初始化为指定值" class="header-anchor">#</a> 直接初始化为指定值</h4> <div class="language-python extra-class"><pre class="language-python"><code>module<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
</code></pre></div><h4 id="使用-torch-nn-init-中的方法"><a href="#使用-torch-nn-init-中的方法" class="header-anchor">#</a> 使用 <code>torch.nn.init</code> 中的方法</h4> <div class="language-python extra-class"><pre class="language-python"><code>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_uniform<span class="token punctuation">(</span>conv1<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>module<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="对于-nn-module-包括-nn-sequential"><a href="#对于-nn-module-包括-nn-sequential" class="header-anchor">#</a> 对于 <code>nn.Module</code>（包括 <code>nn.Sequential</code>）</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">init_weights</span><span class="token punctuation">(</span>module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 判断 module 类型</span>
    <span class="token keyword">if</span> <span class="token builtin">type</span><span class="token punctuation">(</span>module<span class="token punctuation">)</span> <span class="token operator">==</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">:</span>
        nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_uniform<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
        <span class="token comment"># or</span>
        m<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">0.01</span><span class="token punctuation">)</span>
    <span class="token comment"># 也可以这样判断 module 类型</span>
    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
        nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>module<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'fan_in'</span><span class="token punctuation">,</span> nonlinearity<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> module<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>module<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>

net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>init_weights<span class="token punctuation">)</span>
</code></pre></div><h2 id="模型的评估"><a href="#模型的评估" class="header-anchor">#</a> 模型的评估</h2> <ol><li>加载模型：<code>model.load_state_dict(torch.load(&quot;the path of model's pth file&quot;))</code></li> <li>切换到评估模式：<code>model.eval()</code> （为什么要手动指明模型？因为有些东西在训练模式和评估模式下表现不同，例如 Batch Normalization，Dropout）。</li> <li>关闭模型参数的 <code>requires_grad</code>：</li></ol> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">toggle_grad</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> on_or_off<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    param<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> on_or_off
</code></pre></div><ol start="4"><li>准备相应的特征和标签，注意要指明放到 GPU 的内存里，例如 <code>x = torch.randn(10, 128).cuda()</code>。</li> <li>使用模型进行预测，例如：<code>predict = model(x)</code>。</li> <li>最后如果还要继续训练，记得开启模型参数的 <code>requires_grad</code>。</li></ol> <h2 id="模型的保存与加载"><a href="#模型的保存与加载" class="header-anchor">#</a> 模型的保存与加载</h2> <p>注意，有时参数的后缀为 <code>ckpt</code>，即 checkpoint 的缩写。</p> <h3 id="保存模型"><a href="#保存模型" class="header-anchor">#</a> 保存模型</h3> <ol><li>只保存模型参数：torch.save(net.state_dict(), &quot;./data/net_parameter.pth&quot;)</li> <li>保存完整的模型（可能会由于设备和目录的改变而出问题）：torch.save(net, './data/net_model.pth')</li> <li>注意如果还要继续训练的话，还需要保存 optimizer 的 state_dict。</li></ol> <h3 id="加载模型"><a href="#加载模型" class="header-anchor">#</a> 加载模型</h3> <ol><li>加载模型参数：net_clone.load_state_dict(torch.load(&quot;./data/net_parameter.pth&quot;))</li> <li>加载完整的模型（区别在于这里的返回值直接是模型，我们不需要事先构造模型）：net_loaded = torch.load('./data/net_model.pth')</li> <li>如果还要继续训练,则还需要加载 optimizer 的参数，当然如果只是使用训练好的模型的话就不需要了。</li></ol> <h2 id="参考"><a href="#参考" class="header-anchor">#</a> 参考</h2> <ol><li>https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.3_linear-regression-pytorch</li> <li>https://discuss.pytorch.org/t/saving-and-loading-a-model-in-pytorch/2610/2</li> <li>https://stackoverflow.com/questions/49433936/how-to-initialize-weights-in-pytorch</li></ol></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/songquanpeng/cs-notes/edit/main/docs/frameworks/PyTorch/model.md" target="_blank" rel="noopener noreferrer">编辑本页面</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">3/18/2021, 2:56:33 PM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/frameworks/PyTorch/data.html" class="prev">
        PyTorch 数据处理
      </a></span> <span class="next"><a href="/frameworks/PyTorch/optimizer.html">
        PyTorch 优化器
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.bf805b70.js" defer></script><script src="/assets/js/2.9b539265.js" defer></script><script src="/assets/js/11.c97887ff.js" defer></script>
  </body>
</html>
