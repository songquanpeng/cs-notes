<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>PyTorch Tensor | 编程笔记</title>
    <meta name="generator" content="VuePress 1.8.2">
    <script data-ad-client="ca-pub-4932639067711253" async="true" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <meta name="description" content="JustSong 的编程笔记">
    
    <link rel="preload" href="/assets/css/0.styles.d48c97ed.css" as="style"><link rel="preload" href="/assets/js/app.e8367b2c.js" as="script"><link rel="preload" href="/assets/js/2.cd3a5dec.js" as="script"><link rel="preload" href="/assets/js/28.d9ac7f57.js" as="script"><link rel="prefetch" href="/assets/js/10.595a438c.js"><link rel="prefetch" href="/assets/js/11.547ecc25.js"><link rel="prefetch" href="/assets/js/12.12079e7b.js"><link rel="prefetch" href="/assets/js/13.631a4622.js"><link rel="prefetch" href="/assets/js/14.d42dd4ef.js"><link rel="prefetch" href="/assets/js/15.128d010c.js"><link rel="prefetch" href="/assets/js/16.b086132c.js"><link rel="prefetch" href="/assets/js/17.37bfe4a7.js"><link rel="prefetch" href="/assets/js/18.d677db9a.js"><link rel="prefetch" href="/assets/js/19.da00d9bd.js"><link rel="prefetch" href="/assets/js/20.499b1bf5.js"><link rel="prefetch" href="/assets/js/21.4d45d9be.js"><link rel="prefetch" href="/assets/js/22.fa9d66a4.js"><link rel="prefetch" href="/assets/js/23.2f1414f9.js"><link rel="prefetch" href="/assets/js/24.4703d67a.js"><link rel="prefetch" href="/assets/js/25.d018b268.js"><link rel="prefetch" href="/assets/js/26.829a3b6a.js"><link rel="prefetch" href="/assets/js/27.d5eafb3c.js"><link rel="prefetch" href="/assets/js/29.80df66d7.js"><link rel="prefetch" href="/assets/js/3.dfa78226.js"><link rel="prefetch" href="/assets/js/30.3569386f.js"><link rel="prefetch" href="/assets/js/31.f429f193.js"><link rel="prefetch" href="/assets/js/32.a77227ca.js"><link rel="prefetch" href="/assets/js/33.c8a3fe33.js"><link rel="prefetch" href="/assets/js/34.ba1c65f6.js"><link rel="prefetch" href="/assets/js/35.f38fa9b1.js"><link rel="prefetch" href="/assets/js/36.db0a7b01.js"><link rel="prefetch" href="/assets/js/37.9dd56813.js"><link rel="prefetch" href="/assets/js/38.48a34bc7.js"><link rel="prefetch" href="/assets/js/39.52186d1e.js"><link rel="prefetch" href="/assets/js/4.dc748b97.js"><link rel="prefetch" href="/assets/js/40.cd0314fb.js"><link rel="prefetch" href="/assets/js/41.823ecb67.js"><link rel="prefetch" href="/assets/js/42.db0ec2a0.js"><link rel="prefetch" href="/assets/js/43.a1a1825b.js"><link rel="prefetch" href="/assets/js/44.42316137.js"><link rel="prefetch" href="/assets/js/45.cb5d78e2.js"><link rel="prefetch" href="/assets/js/46.78ebaeff.js"><link rel="prefetch" href="/assets/js/47.37d6c890.js"><link rel="prefetch" href="/assets/js/48.d5bff22b.js"><link rel="prefetch" href="/assets/js/5.1f6e190a.js"><link rel="prefetch" href="/assets/js/6.924b111d.js"><link rel="prefetch" href="/assets/js/7.0765b61d.js"><link rel="prefetch" href="/assets/js/8.28c3180c.js"><link rel="prefetch" href="/assets/js/9.623423e7.js">
    <link rel="stylesheet" href="/assets/css/0.styles.d48c97ed.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">编程笔记</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  主页
</a></div><div class="nav-item"><a href="/languages/" class="nav-link">
  语言
</a></div><div class="nav-item"><a href="/frameworks/" class="nav-link router-link-active">
  框架
</a></div><div class="nav-item"><a href="/tools/" class="nav-link">
  工具
</a></div><div class="nav-item"><a href="/algorithms/" class="nav-link">
  算法
</a></div><div class="nav-item"><a href="/others/" class="nav-link">
  其他
</a></div><div class="nav-item"><a href="https://iamazing.cn" target="_blank" rel="noopener noreferrer" class="nav-link external">
  博客
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <a href="https://github.com/songquanpeng/cs-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  主页
</a></div><div class="nav-item"><a href="/languages/" class="nav-link">
  语言
</a></div><div class="nav-item"><a href="/frameworks/" class="nav-link router-link-active">
  框架
</a></div><div class="nav-item"><a href="/tools/" class="nav-link">
  工具
</a></div><div class="nav-item"><a href="/algorithms/" class="nav-link">
  算法
</a></div><div class="nav-item"><a href="/others/" class="nav-link">
  其他
</a></div><div class="nav-item"><a href="https://iamazing.cn" target="_blank" rel="noopener noreferrer" class="nav-link external">
  博客
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <a href="https://github.com/songquanpeng/cs-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Linux</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Algorithms</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Frameworks</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/frameworks/" aria-current="page" class="sidebar-link">/frameworks/</a></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading open"><span>Py Torch</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/frameworks/PyTorch/" aria-current="page" class="sidebar-link">PyTorch 概述</a></li><li><a href="/frameworks/PyTorch/data.html" class="sidebar-link">PyTorch 数据处理</a></li><li><a href="/frameworks/PyTorch/model.html" class="sidebar-link">PyTorch 模型</a></li><li><a href="/frameworks/PyTorch/optimizer.html" class="sidebar-link">PyTorch 优化器</a></li><li><a href="/frameworks/PyTorch/tensor.html" aria-current="page" class="active sidebar-link">PyTorch Tensor</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/tensor.html#概述" class="sidebar-link">概述</a></li><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/tensor.html#tensor-的创建" class="sidebar-link">Tensor 的创建</a></li><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/tensor.html#tensor-的操作" class="sidebar-link">Tensor 的操作</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/tensor.html#获取-tensor-的属性" class="sidebar-link">获取 Tensor 的属性</a></li><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/tensor.html#算数操作" class="sidebar-link">算数操作</a></li><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/tensor.html#索引操作" class="sidebar-link">索引操作</a></li><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/tensor.html#改变形状" class="sidebar-link">改变形状</a></li><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/tensor.html#其他操作" class="sidebar-link">其他操作</a></li></ul></li><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/tensor.html#梯度的计算" class="sidebar-link">梯度的计算</a></li><li class="sidebar-sub-header"><a href="/frameworks/PyTorch/tensor.html#参考" class="sidebar-link">参考</a></li></ul></li><li><a href="/frameworks/PyTorch/torchvision.html" class="sidebar-link">TorchVision 相关笔记</a></li><li><a href="/frameworks/PyTorch/trick.html" class="sidebar-link">PyTorch 使用技巧</a></li></ul></section></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Languages</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Others</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Tools</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="pytorch-tensor"><a href="#pytorch-tensor" class="header-anchor">#</a> PyTorch Tensor</h1> <h2 id="概述"><a href="#概述" class="header-anchor">#</a> 概述</h2> <p><code>torch.Tensor</code> 与 NumPy 的多维数组非常类似，区别在于：</p> <ol><li>GPU 计算。</li> <li>自动求梯度。</li></ol> <h2 id="tensor-的创建"><a href="#tensor-的创建" class="header-anchor">#</a> Tensor 的创建</h2> <ol><li><p>创建未初始化的 Tensor：<code>torch.empty(*sizes)</code></p></li> <li><p>创建随机初始化的 Tensor：</p> <ol><li>均匀分布（从区间 [0, 1) 中均匀取样）：<code>torch.rand(*sizes)</code></li> <li>标准正态分布（均值为 0，方差为 1）：<code>torch.randn(*sizes)</code></li> <li>离散正态分布（可以分别为每个量指定 mean 和 std）：
<ol><li><code>torch.normal(mean, std, sizes)</code></li> <li><code>torch.normal(means, stds)</code></li> <li><code>torch.normal(means, std)</code></li> <li><code>torch.normal(mean, stds)</code></li></ol></li></ol></li> <li><p>创建指定值的 Tensor：</p> <ol><li>全 0：<code>torch.zeros(x, y)</code></li> <li>全 1：<code>torch.ones(x, y)</code></li> <li>全 n：<code>torch.ones(x, y) * n</code></li> <li>对角线为 1，其余为 0：<code>torch.eye(x, y)</code></li> <li>等宽数列：
<ol><li>定步长：<code>torch.arange(s, e, step)</code></li> <li>定个数：<code>torch.linspace(s, e, steps)</code></li></ol></li></ol></li> <li><p>从数据创建：</p> <ol><li>从 Python 列表或 Numpy 数组：<code>torch.Tensor([a, b, c])</code></li> <li>从已有的 Tensor：
<ol><li><code>x = x.new_ones()</code></li></ol></li></ol></li></ol> <p>创建时可指定：</p> <ol><li>数据类型：<code>dtype=torch.float</code>，具体参见<a href="https://pytorch.org/docs/stable/Tensors.html" target="_blank" rel="noopener noreferrer">官网上的类型列表<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。</li> <li>是否需要梯度更新：<code>requires_grad=True</code></li> <li>设备：<code>device='cpu'</code> 或者 <code>device=torch.device('cuda')</code>：
<ol><li>CPU：<code>torch.device('cpu')</code></li> <li>当前 cuda 设备：<code>torch.device('cuda')</code></li> <li>指定 cuda 设备：<code>torch.device('cuda:0')</code></li></ol></li></ol> <p>也可之后在设备间移动 Tensor：<code>x = x.to(device)</code></p> <p>注意，这种直接创建的 tensor 为叶子节点：<code>x.is_leaf = True</code>。</p> <h2 id="tensor-的操作"><a href="#tensor-的操作" class="header-anchor">#</a> Tensor 的操作</h2> <h3 id="获取-tensor-的属性"><a href="#获取-tensor-的属性" class="header-anchor">#</a> 获取 Tensor 的属性</h3> <p>获取形状：</p> <ol><li><code>x.size()</code></li> <li><code>x.shape</code>
返回值为形状元组。</li></ol> <p>获取维度：<code>x.dim()</code>，返回值为 int。</p> <h3 id="算数操作"><a href="#算数操作" class="header-anchor">#</a> 算数操作</h3> <p>一般而言，有以下形式：</p> <ol><li>用 Python 的运算符：
<ol><li><code>y = x + y</code>（开辟了新内存，并将 y 指向新内存）</li> <li><code>y[:] = x + y</code>（没有开辟新内存）</li></ol></li> <li>用 PyTorch 提供的函数：
<ol><li><code>y = torch.add(x, y)</code>（开辟了新内存，并将 y 指向新内存）</li> <li><code>torch.add(x, y, out=y)</code>（没有开辟新内存）</li> <li><code>y.add_(x)</code>（没有开辟新内存）</li></ol></li></ol> <p>注意所有后面带有下划线的函数均表示该操作直接作用于当前矩阵（inplace）。</p> <h3 id="索引操作"><a href="#索引操作" class="header-anchor">#</a> 索引操作</h3> <p>类似 NumPy。
例子：
取 x 的第一行的元素：<code>y = x[0, :]</code>。</p> <p>注意： x 和 y 是共享内存的。</p> <h3 id="改变形状"><a href="#改变形状" class="header-anchor">#</a> 改变形状</h3> <p><code>y = x.view(sizes*)</code></p> <p>注意：x 和 y 同样是共享内存的，如果不想共享内存，则 <code>y = x.clone().view(sizes*)</code>。</p> <p>可以有一个值为 -1，这样 PyTorch 会自动推断该值。</p> <p>例子：</p> <ol><li>将图片输入全连接层：<code>linear(x.view(x.shape[0], -1))</code>，shape 的第一个值是 batch size。</li></ol> <h3 id="其他操作"><a href="#其他操作" class="header-anchor">#</a> 其他操作</h3> <table><thead><tr><th style="text-align:left;">操作</th> <th style="text-align:left;">描述</th></tr></thead> <tbody><tr><td style="text-align:left;"><code>x.clone()</code> 或 <code>torch.clone(x)</code></td> <td style="text-align:left;">拷贝 x 的一个副本，注意该操作会被记录在计算图中，梯度回传到副本时也会传到源 Tensor</td></tr> <tr><td style="text-align:left;"><code>x.detach()</code></td> <td style="text-align:left;">返回一个新的 Tensor，其从当前计算图中剥离，但是注意内存是共享的，如果对其进行修改将出发错误</td></tr> <tr><td style="text-align:left;"><code>x.detach_()</code></td> <td style="text-align:left;">将当前 Tensor 从计算图中剥离，使其成为叶子节点，注意不能对 view 使用该函数</td></tr> <tr><td style="text-align:left;"><code>x.requires_grad_(requires_grad=True)</code></td> <td style="text-align:left;">设置 x 为需要梯度信息</td></tr> <tr><td style="text-align:left;"><code>x.item()</code></td> <td style="text-align:left;">x 必须为 0 维度，返回其值，类型为 Python 内置类型</td></tr> <tr><td style="text-align:left;"><code>x.float()</code></td> <td style="text-align:left;">返回一个新的指定类型的张量</td></tr> <tr><td style="text-align:left;"><code>x.mean()</code></td> <td style="text-align:left;">返回一个张量，其为 x 的均值，注意 x 必须是浮点类型</td></tr> <tr><td style="text-align:left;"><code>x.gather(dim, index)</code></td> <td style="text-align:left;"></td></tr> <tr><td style="text-align:left;"><code>x.argmax(dim)</code></td> <td style="text-align:left;">返回指定维度上最大值的索引</td></tr> <tr><td style="text-align:left;"><code>x.numpy()</code></td> <td style="text-align:left;">返回张量 x 的 numpy 数据形式，注意内存是共享的</td></tr></tbody></table> <h2 id="梯度的计算"><a href="#梯度的计算" class="header-anchor">#</a> 梯度的计算</h2> <ol><li>Tensor 的属性 <code>requires_grad</code> 若为 <code>True</code>，则 PyTorch 将追踪其上的操作。</li> <li>通过 inpalce 函数 <code>x.requires_grad_(boolean)</code> 可设置该属性。</li> <li>使用 <code>with torch.no_grad()</code> 可禁用一整块的代码中的 Tensor 中的梯度计算。
<blockquote><ul><li><code>model.eval()</code> will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.</li> <li><code>torch.no_grad()</code> impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you won’t be able to backprop.</li></ul></blockquote></li> <li>Tensor 的 <code>grad_fn</code> 属性记录了该 Tensor 是由什么操作产生的。</li> <li>之后调用 <code>x.backward()</code> 进行反向传播，梯度将记录在 Tensor 的 <code>grad</code> 属性中。</li></ol> <p>一般流程：</p> <ol><li><code>optimizer.zero_grad()</code>：清空梯度，或者遍历所有参数，通过 <code>param.grad.data.zero_()</code> 手动清空。</li> <li><code>loss.backward()</code>：反向传播，计算新的梯度。</li> <li><code>optimizer.step()</code>：根据梯度对 Tensor（参数）进行更新。</li></ol> <p>注意，对于标量，直接调用 <code>x.backward()</code> 即可，否则需要传入一个同形状的权重：<code>x.backward(w)</code>。
这样做的目的是避免 Tensor 对 Tensor 求导，实际上可以理解为 <code>l = torch.sum(x*w)</code>，具体参见<a href="https://zhuanlan.zhihu.com/p/29923090" target="_blank" rel="noopener noreferrer">这里的解释<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。</p> <p>一般情况下最终的 loss 都是标量。</p> <h2 id="参考"><a href="#参考" class="header-anchor">#</a> 参考</h2> <ol><li><a href="https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter02_prerequisite/2.2_Tensor" target="_blank" rel="noopener noreferrer">https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter02_prerequisite/2.2_Tensor<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://zhuanlan.zhihu.com/p/29923090" target="_blank" rel="noopener noreferrer">PyTorch 的 backward 为什么有一个 grad_variables 参数 ？<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615/2?u=justsong" target="_blank" rel="noopener noreferrer">‘model.eval()’ vs ‘with torch.no_grad()’<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://discuss.pytorch.org/t/what-step-backward-and-zero-grad-do/33301" target="_blank" rel="noopener noreferrer">What step(), backward(), and zero_grad() do<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ol></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/songquanpeng/cs-notes/edit/main/docs/frameworks/PyTorch/tensor.md" target="_blank" rel="noopener noreferrer">编辑本页面</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">3/19/2021, 3:44:07 PM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/frameworks/PyTorch/optimizer.html" class="prev">
        PyTorch 优化器
      </a></span> <span class="next"><a href="/frameworks/PyTorch/torchvision.html">
        TorchVision 相关笔记
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.e8367b2c.js" defer></script><script src="/assets/js/2.cd3a5dec.js" defer></script><script src="/assets/js/28.d9ac7f57.js" defer></script>
  </body>
</html>
