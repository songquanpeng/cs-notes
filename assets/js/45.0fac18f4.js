(window.webpackJsonp=window.webpackJsonp||[]).push([[45],{404:function(t,a,n){"use strict";n.r(a);var s=n(44),e=Object(s.a)({},(function(){var t=this,a=t.$createElement,n=t._self._c||a;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"pytorch-模型"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#pytorch-模型"}},[t._v("#")]),t._v(" PyTorch 模型")]),t._v(" "),n("h2",{attrs:{id:"模型的构建"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#模型的构建"}},[t._v("#")]),t._v(" 模型的构建")]),t._v(" "),n("p",[t._v("实际上模型层和模型没有本质区别，其对外提供的接口一致。")]),t._v(" "),n("p",[n("code",[t._v("nn.module")]),t._v(" 实现了 "),n("code",[t._v("__call__")]),t._v(" 函数，因此我们可以直接通过模型来调用，无须手动调用 "),n("code",[t._v("forward()")]),t._v(" 函数。")]),t._v(" "),n("p",[t._v("继承自 "),n("code",[t._v("Module")]),t._v(" 的类还有："),n("code",[t._v("Sequential")]),t._v("，"),n("code",[t._v("ModuleList")]),t._v(" 以及 "),n("code",[t._v("ModuleDict")]),t._v("。")]),t._v(" "),n("h3",{attrs:{id:"使用-nn-module-进行构建"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#使用-nn-module-进行构建"}},[t._v("#")]),t._v(" 使用 "),n("code",[t._v("nn.module")]),t._v(" 进行构建")]),t._v(" "),n("p",[t._v("这是通过继承 "),n("code",[t._v("nn.module")]),t._v(" 来构造网络。")]),t._v(" "),n("p",[t._v("该方式的最大优点是灵活，比如说可以自由地复用网络层。")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("MyNet")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_feature"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("super")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("MyNet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("linear "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_feature"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("forward")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        y "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" y\n\nnet "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" MyNet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_feature"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h3",{attrs:{id:"使用-nn-sequelize-进行构建"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#使用-nn-sequelize-进行构建"}},[t._v("#")]),t._v(" 使用 "),n("code",[t._v("nn.Sequelize")]),t._v(" 进行构建")]),t._v(" "),n("p",[t._v("nn.Sequelize 内置了一个有序字典，因此前向传播时模块的执行顺序与加入的顺序相同。")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用构造函数")]),t._v("\nnet "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Sequential"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用列表")]),t._v("\nlayers "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nlayers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ConvTranspose2d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlayers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("InstanceNorm2d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnet "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Sequential"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("layers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用有序字典，可以指定网络层名字")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" collections "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" OrderedDict\nnet "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Sequential"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("OrderedDict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'linear'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'linear'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'linear'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用 add_module 来进行构建")]),t._v("\nnet "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Sequential"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"linear1"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"relu1"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ReLU"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"linear2"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"relu2"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ReLU"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"linear3"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sigmoid"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Sigmoid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h3",{attrs:{id:"使用-nn-modulelist-进行构建"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#使用-nn-modulelist-进行构建"}},[t._v("#")]),t._v(" 使用 "),n("code",[t._v("nn.ModuleList()")]),t._v(" 进行构建")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("encode "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ModuleList"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nself"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("decode "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ModuleList"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nself"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("encode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ResBlk"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dim_in"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dim_out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nself"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("decode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("insert"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" AdainResBlk"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dim_out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dim_in"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("与 "),n("code",[t._v("nn.Sequelize")]),t._v(" 的区别："),n("code",[t._v("nn.Sequential")]),t._v(" 是一个 module，其有 forward 函数，因此可以拿来直接输入。")]),t._v(" "),n("p",[n("code",[t._v("nn.ModuleList()")]),t._v(" 相当于一个列表，其中的网络层之间没有联系，不保证次序。")]),t._v(" "),n("p",[t._v("不同于直接使用列表的方式，ModuleList 中的所有模块参数会被自动加入到网络中，可以被优化器发现和训练。")]),t._v(" "),n("h3",{attrs:{id:"使用-nn-moduledict-进行构建"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#使用-nn-moduledict-进行构建"}},[t._v("#")]),t._v(" 使用 "),n("code",[t._v("nn.ModuleDict()")]),t._v(" 进行构建")]),t._v(" "),n("p",[t._v("与 "),n("code",[t._v("ModuleList")]),t._v(" 类似，同样没有实现 "),n("code",[t._v("forward")]),t._v(" 函数，不过这里换成了字典：")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("net "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ModuleDict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'linear'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("784")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("256")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'act'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ReLU"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 可以像字典那样添加元素")]),t._v("\nnet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'output'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("256")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h3",{attrs:{id:"构建自定义网络层"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#构建自定义网络层"}},[t._v("#")]),t._v(" 构建自定义网络层")]),t._v(" "),n("p",[t._v("虽说模型和模型层没有本质区别，都是 "),n("code",[t._v("Module")]),t._v("，但是对于模型层，构建的时候我们要注意参数的声明和使用。")]),t._v(" "),n("p",[t._v("为什么构建模型时不用管呢？因为模型里用的都是现有的模型层，其参数已经声明好了（可能也已经初始化好了）。")]),t._v(" "),n("p",[t._v("注意有的层不需要参数，自然也不用管。")]),t._v(" "),n("p",[t._v("模型参数的类型可以为：")]),t._v(" "),n("ol",[n("li",[n("code",[t._v("nn.Parameter")]),t._v("：单个参数，通过参数名访问。")]),t._v(" "),n("li",[n("code",[t._v("nn.ParameterList")]),t._v("：参数列表，通过索引访问。")])]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("params "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ParameterList"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Parameter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("randn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("ol",{attrs:{start:"3"}},[n("li",[n("code",[t._v("nn.ParameterDict")]),t._v("：参数字典，通过 key 访问。")])]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("params "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ParameterDict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'linear1'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Parameter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("randn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'linear2'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Parameter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("randn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("至于参数的使用，无非是与输入等做一些计算。")]),t._v(" "),n("h3",{attrs:{id:"常用网络层"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#常用网络层"}},[t._v("#")]),t._v(" 常用网络层")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_inputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_outputs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ReLU"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h3",{attrs:{id:"查看模型结构"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#查看模型结构"}},[t._v("#")]),t._v(" 查看模型结构")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("查看每一层的输出是否正常：")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("X "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rand"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("N"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" C"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" H"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" W"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" layer "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("named_children"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    X "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" layer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("' output shape:\\t'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" X"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h2",{attrs:{id:"模型的参数"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#模型的参数"}},[t._v("#")]),t._v(" 模型的参数")]),t._v(" "),n("p",[n("code",[t._v("Module")]),t._v(" 类实现了两个相关的函数：")]),t._v(" "),n("ol",[n("li",[n("code",[t._v("parameters()")]),t._v("：返回参数迭代器。")]),t._v(" "),n("li",[n("code",[t._v("named_parameters()")]),t._v("：返回 (名字, 参数) 元组迭代器，名字即参数的变量名。")])]),t._v(" "),n("p",[t._v("参数的类型为 "),n("code",[t._v("torch.nn.Parameter")]),t._v("，其是 Tensor 的子类，特殊之处在于其内的值会自动加入到参数列表。")]),t._v(" "),n("h2",{attrs:{id:"模型的非参数-tensor"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#模型的非参数-tensor"}},[t._v("#")]),t._v(" 模型的非参数 Tensor")]),t._v(" "),n("p",[t._v("用于保存非参数的 Tensor，这些 Tensor 又需要保存在 state_dict 之中。")]),t._v(" "),n("p",[t._v("注册方法："),n("code",[t._v("self.register_buffer('running_mean', torch.zeros(num_features))")])]),t._v(" "),n("p",[t._v("使用方法："),n("code",[t._v("self.running_mean")])]),t._v(" "),n("h3",{attrs:{id:"对于单个网络层的参数初始化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#对于单个网络层的参数初始化"}},[t._v("#")]),t._v(" 对于单个网络层的参数初始化")]),t._v(" "),n("h4",{attrs:{id:"直接初始化为指定值"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#直接初始化为指定值"}},[t._v("#")]),t._v(" 直接初始化为指定值")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("weight"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fill_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h4",{attrs:{id:"使用-torch-nn-init-中的方法"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#使用-torch-nn-init-中的方法"}},[t._v("#")]),t._v(" 使用 "),n("code",[t._v("torch.nn.init")]),t._v(" 中的方法")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("init"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xavier_uniform"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conv1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("weight"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("init"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("constant_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bias"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("init"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("norm_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("weight"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mean"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" std"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h3",{attrs:{id:"对于-nn-module的参数初始化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#对于-nn-module的参数初始化"}},[t._v("#")]),t._v(" 对于 "),n("code",[t._v("nn.Module")]),t._v("的参数初始化")]),t._v(" "),n("p",[t._v("包括 "),n("code",[t._v("nn.Sequential")]),t._v("。")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用内置的初始化方法")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" param "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("named_parameters"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'weight'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        init"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("normal_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("param"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mean"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" std"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'bias'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        init"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("constant_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("param"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 自定义参数初始化方法")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("no_grad")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("init_weights")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 判断 module 类型")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("init"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xavier_uniform"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("m"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("weight"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# or")]),t._v("\n        m"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bias"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fill_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 也可以这样判断 module 类型")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Conv2d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("init"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("kaiming_normal_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("weight"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mode"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'fan_in'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nonlinearity"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'relu'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bias "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("init"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("constant_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bias"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nnet "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Sequential"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Linear"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("apply")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("init_weights"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("要注意，要么在 "),n("code",[t._v("with torch.no_grad()")]),t._v(" 里进行参数的初始化操作，要么加上 "),n("code",[t._v("@torch.no_grad()")]),t._v(" 注解。")]),t._v(" "),n("p",[t._v("对于内置的参数初始化函数，其已经做了类似的处理，例如对于 "),n("code",[t._v("nn.init.xavier_uniform")]),t._v("：")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("xavier_uniform_")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tensor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Tensor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" gain"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" Tensor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    fan_in"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fan_out "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" _calculate_fan_in_and_fan_out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tensor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    std "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" gain "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" math"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqrt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.0")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fan_in "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" fan_out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    a "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" math"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqrt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" std  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Calculate uniform bounds from standard deviation")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" _no_grad_uniform_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tensor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("_no_grad_uniform_")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tensor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("no_grad"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" tensor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("uniform_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("当然，如果是直接操作 "),n("code",[t._v(".data")]),t._v(" 属性，那 "),n("code",[t._v("no_grad")]),t._v(" 不是必须的（因为这样的话本来就不会被自动求导机制记录）。")]),t._v(" "),n("h3",{attrs:{id:"模型参数的共享"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#模型参数的共享"}},[t._v("#")]),t._v(" 模型参数的共享")]),t._v(" "),n("p",[t._v("直接使用同一个 "),n("code",[t._v("Module")]),t._v(" 实例就好。")]),t._v(" "),n("p",[t._v("反向传播时梯度会累加。")]),t._v(" "),n("h2",{attrs:{id:"模型的评估"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#模型的评估"}},[t._v("#")]),t._v(" 模型的评估")]),t._v(" "),n("ol",[n("li",[t._v("加载模型："),n("code",[t._v('model.load_state_dict(torch.load("the path of model\'s pth file"))')])]),t._v(" "),n("li",[t._v("切换到评估模式："),n("code",[t._v("model.eval()")]),t._v(" ；\n"),n("ol",[n("li",[t._v("为什么要手动指明模式？因为有些东西在训练模式和评估模式下表现不同，例如 Batch Normalization，Dropout。")]),t._v(" "),n("li",[t._v("具体是如何实现的？调用 "),n("code",[t._v("eval()")]),t._v(" 后会将模型的 training 属性置为 false，Batch Normalization layer 或者 Dropout layer 通过读取 training 属性来判断当前模式从而采用不同的行为。")]),t._v(" "),n("li",[n("strong",[t._v("要注意，eval 不会影响梯度的计算，只不过不回传更新参数而已，必须另外额外关闭梯度计算")])])])]),t._v(" "),n("li",[t._v("关闭模型参数的 "),n("code",[t._v("requires_grad")]),t._v("：")])]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toggle_grad")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" on_or_off"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" param "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parameters"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    param"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("requires_grad "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" on_or_off\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 或者使用 torch.no_grad() 装饰器或者 with 代码块。")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("no_grad"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    out_data "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("之后网络前向传播后不会再进行求导和进行反向传播。")]),t._v(" "),n("ol",{attrs:{start:"4"}},[n("li",[t._v("准备相应的特征和标签，注意要指明放到 GPU 的内存里，例如 "),n("code",[t._v("x = torch.randn(10, 128).cuda()")]),t._v("。")]),t._v(" "),n("li",[t._v("使用模型进行预测，例如："),n("code",[t._v("predict = model(x)")]),t._v("。")]),t._v(" "),n("li",[t._v("最后如果还要继续训练，记得：\n"),n("ol",[n("li",[t._v("开启模型参数的 "),n("code",[t._v("requires_grad")]),t._v("（如果使用 "),n("code",[t._v("torch.no_grad()")]),t._v("，结束该 with 块之后 "),n("code",[t._v("requires_grad")]),t._v(" 会自动恢复成 "),n("code",[t._v("Ture")]),t._v("），")]),t._v(" "),n("li",[t._v("并调用 "),n("code",[t._v("model.train()")]),t._v("。")])])])]),t._v(" "),n("h2",{attrs:{id:"模型的保存与加载"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#模型的保存与加载"}},[t._v("#")]),t._v(" 模型的保存与加载")]),t._v(" "),n("p",[t._v("参数后缀任意，一般为 "),n("code",[t._v("pt")]),t._v(" 或 "),n("code",[t._v("pth")]),t._v("。\n注意，有时参数的后缀为 "),n("code",[t._v("ckpt")]),t._v("，即 checkpoint 的缩写。")]),t._v(" "),n("p",[t._v("两种类型，第一种是通过 "),n("code",[t._v("state_dict")]),t._v("。")]),t._v(" "),n("p",[t._v("该方式和 Tensor 的保存与加载没有本质区别。")]),t._v(" "),n("p",[t._v("用到两个函数：")]),t._v(" "),n("ol",[n("li",[n("code",[t._v("model.state_dict()")]),t._v(" ：返回一个映射参数名称到对应 Tensor 的字典对象。")]),t._v(" "),n("li",[n("code",[t._v("model.load_state_dict(dict)")]),t._v(" ：接受一个字典，使用其内的值初始化模型参数。")])]),t._v(" "),n("p",[t._v("自然，只有有可学习的参数（"),n("code",[t._v("nn.Parameter")]),t._v("）的网络层有这两个方法。")]),t._v(" "),n("p",[t._v("另外，优化器也有这两个方法，用以存储其状态和所使用的超参数。")]),t._v(" "),n("p",[t._v("这里并没有魔法，只是 Tensor 的存储与加载罢了。")]),t._v(" "),n("p",[t._v("第二种是通过以下两个函数：")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("save"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" PATH"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("PATH"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("这种看起来更加方便，我们取回的时候甚至都不用实现准备模型实例，但是，序列化后的模型与具体的类和目录结构绑定在一起了，\n如果后续文件位置或者类发生改变，模型将不可用，因此不推荐这种方式。")]),t._v(" "),n("p",[t._v("要注意，加载后的模型默认是训练模式，如果要进行评估，必须手动切换。")]),t._v(" "),n("h3",{attrs:{id:"保存模型"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#保存模型"}},[t._v("#")]),t._v(" 保存模型")]),t._v(" "),n("ol",[n("li",[t._v('只保存模型参数：torch.save(net.state_dict(), "./data/net_parameter.pth")')]),t._v(" "),n("li",[t._v("保存完整的模型（可能会由于设备和目录的改变而出问题）：torch.save(net, './data/net_model.pth')")]),t._v(" "),n("li",[t._v("注意如果还要继续训练的话，还需要保存 optimizer 的 state_dict。")])]),t._v(" "),n("h3",{attrs:{id:"加载模型"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#加载模型"}},[t._v("#")]),t._v(" 加载模型")]),t._v(" "),n("ol",[n("li",[t._v('加载模型参数：net_clone.load_state_dict(torch.load("./data/net_parameter.pth"))')]),t._v(" "),n("li",[t._v("加载完整的模型（区别在于这里的返回值直接是模型，我们不需要事先构造模型）：net_loaded = torch.load('./data/net_model.pth')")]),t._v(" "),n("li",[t._v("如果还要继续训练,则还需要加载 optimizer 的参数，当然如果只是使用训练好的模型的话就不需要了。")])]),t._v(" "),n("h2",{attrs:{id:"参考"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#参考"}},[t._v("#")]),t._v(" 参考")]),t._v(" "),n("ol",[n("li",[n("a",{attrs:{href:"https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.3_linear-regression-pytorch",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.3_linear-regression-pytorch"),n("OutboundLink")],1)]),t._v(" "),n("li",[n("a",{attrs:{href:"https://discuss.pytorch.org/t/saving-and-loading-a-model-in-pytorch/2610/2",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://discuss.pytorch.org/t/saving-and-loading-a-model-in-pytorch/2610/2"),n("OutboundLink")],1)]),t._v(" "),n("li",[n("a",{attrs:{href:"https://stackoverflow.com/questions/49433936/how-to-initialize-weights-in-pytorch",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://stackoverflow.com/questions/49433936/how-to-initialize-weights-in-pytorch"),n("OutboundLink")],1)]),t._v(" "),n("li",[n("a",{attrs:{href:"https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter04_DL_computation/4.1_model-construction",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter04_DL_computation/4.1_model-construction"),n("OutboundLink")],1)]),t._v(" "),n("li",[n("a",{attrs:{href:"https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter04_DL_computation/4.2_parameters",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter04_DL_computation/4.2_parameters"),n("OutboundLink")],1)]),t._v(" "),n("li",[n("a",{attrs:{href:"https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter04_DL_computation/4.4_custom-layer",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter04_DL_computation/4.4_custom-layer"),n("OutboundLink")],1)])])])}),[],!1,null,null,null);a.default=e.exports}}]);