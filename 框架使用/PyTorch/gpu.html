<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>使用 GPU 加速计算 | 编程笔记</title>
    <meta name="generator" content="VuePress 1.8.2">
    <script data-ad-client="ca-pub-4932639067711253" async="true" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <meta name="description" content="JustSong 的编程笔记">
    
    <link rel="preload" href="/assets/css/0.styles.f24f2770.css" as="style"><link rel="preload" href="/assets/js/app.c3f39da1.js" as="script"><link rel="preload" href="/assets/js/2.0d6745a2.js" as="script"><link rel="preload" href="/assets/js/41.853a75bd.js" as="script"><link rel="prefetch" href="/assets/js/10.04a7093c.js"><link rel="prefetch" href="/assets/js/11.99c7d178.js"><link rel="prefetch" href="/assets/js/12.f751b69e.js"><link rel="prefetch" href="/assets/js/13.a12ff563.js"><link rel="prefetch" href="/assets/js/14.3f374610.js"><link rel="prefetch" href="/assets/js/15.29345cfd.js"><link rel="prefetch" href="/assets/js/16.1b7c89b3.js"><link rel="prefetch" href="/assets/js/17.f2e5b814.js"><link rel="prefetch" href="/assets/js/18.6b9ac9c1.js"><link rel="prefetch" href="/assets/js/19.cf7dc984.js"><link rel="prefetch" href="/assets/js/20.494e77f9.js"><link rel="prefetch" href="/assets/js/21.ff920d53.js"><link rel="prefetch" href="/assets/js/22.a2f2cf0f.js"><link rel="prefetch" href="/assets/js/23.9907be2c.js"><link rel="prefetch" href="/assets/js/24.eacc5b93.js"><link rel="prefetch" href="/assets/js/25.48c0f461.js"><link rel="prefetch" href="/assets/js/26.59605d23.js"><link rel="prefetch" href="/assets/js/27.429003aa.js"><link rel="prefetch" href="/assets/js/28.141533e4.js"><link rel="prefetch" href="/assets/js/29.61038db6.js"><link rel="prefetch" href="/assets/js/3.31d87108.js"><link rel="prefetch" href="/assets/js/30.749dfcc1.js"><link rel="prefetch" href="/assets/js/31.2f1ac4e1.js"><link rel="prefetch" href="/assets/js/32.6f80f4a3.js"><link rel="prefetch" href="/assets/js/33.2b3032c4.js"><link rel="prefetch" href="/assets/js/34.11195481.js"><link rel="prefetch" href="/assets/js/35.ff00053c.js"><link rel="prefetch" href="/assets/js/36.3afc8c4f.js"><link rel="prefetch" href="/assets/js/37.e81724fe.js"><link rel="prefetch" href="/assets/js/38.44cd6b7e.js"><link rel="prefetch" href="/assets/js/39.8d5ee136.js"><link rel="prefetch" href="/assets/js/4.95d34a0c.js"><link rel="prefetch" href="/assets/js/40.b29fc4b6.js"><link rel="prefetch" href="/assets/js/42.7426b5d7.js"><link rel="prefetch" href="/assets/js/43.7bc0e4f4.js"><link rel="prefetch" href="/assets/js/44.c7d90a1a.js"><link rel="prefetch" href="/assets/js/45.70b686b5.js"><link rel="prefetch" href="/assets/js/46.4c3c0d15.js"><link rel="prefetch" href="/assets/js/47.4d495e1a.js"><link rel="prefetch" href="/assets/js/48.269e1920.js"><link rel="prefetch" href="/assets/js/49.3de1babe.js"><link rel="prefetch" href="/assets/js/5.c3a96cc4.js"><link rel="prefetch" href="/assets/js/50.d640c88f.js"><link rel="prefetch" href="/assets/js/51.6c949190.js"><link rel="prefetch" href="/assets/js/52.09a4eaad.js"><link rel="prefetch" href="/assets/js/53.02889a3e.js"><link rel="prefetch" href="/assets/js/54.444b924a.js"><link rel="prefetch" href="/assets/js/55.6326706a.js"><link rel="prefetch" href="/assets/js/56.99a2d25f.js"><link rel="prefetch" href="/assets/js/57.a09cac81.js"><link rel="prefetch" href="/assets/js/58.4ff2d528.js"><link rel="prefetch" href="/assets/js/59.de574f65.js"><link rel="prefetch" href="/assets/js/6.e3a0505b.js"><link rel="prefetch" href="/assets/js/60.83506b72.js"><link rel="prefetch" href="/assets/js/61.fc90c71f.js"><link rel="prefetch" href="/assets/js/62.96d607f1.js"><link rel="prefetch" href="/assets/js/63.5493abe3.js"><link rel="prefetch" href="/assets/js/64.3a7f3c39.js"><link rel="prefetch" href="/assets/js/7.4eded3f6.js"><link rel="prefetch" href="/assets/js/8.2b0ea8ce.js"><link rel="prefetch" href="/assets/js/9.805f6267.js">
    <link rel="stylesheet" href="/assets/css/0.styles.f24f2770.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">编程笔记</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  主页
</a></div><div class="nav-item"><a href="/编程语言/" class="nav-link">
  语言
</a></div><div class="nav-item"><a href="/框架使用/" class="nav-link">
  框架
</a></div><div class="nav-item"><a href="/工具使用/" class="nav-link">
  工具
</a></div><div class="nav-item"><a href="/算法总结/" class="nav-link">
  算法
</a></div><div class="nav-item"><a href="/Linux 系统/" class="nav-link">
  Linux
</a></div><div class="nav-item"><a href="https://iamazing.cn" target="_blank" rel="noopener noreferrer" class="nav-link external">
  博客
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <a href="https://github.com/songquanpeng/cs-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  主页
</a></div><div class="nav-item"><a href="/编程语言/" class="nav-link">
  语言
</a></div><div class="nav-item"><a href="/框架使用/" class="nav-link">
  框架
</a></div><div class="nav-item"><a href="/工具使用/" class="nav-link">
  工具
</a></div><div class="nav-item"><a href="/算法总结/" class="nav-link">
  算法
</a></div><div class="nav-item"><a href="/Linux 系统/" class="nav-link">
  Linux
</a></div><div class="nav-item"><a href="https://iamazing.cn" target="_blank" rel="noopener noreferrer" class="nav-link external">
  博客
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <a href="https://github.com/songquanpeng/cs-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Linux 系统</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>工具使用</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>框架使用</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>Flask</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading open"><span>Py Torch</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/%E6%A1%86%E6%9E%B6%E4%BD%BF%E7%94%A8/PyTorch/" aria-current="page" class="sidebar-link">PyTorch 概述</a></li><li><a href="/框架使用/PyTorch/data.html" class="sidebar-link">PyTorch 数据处理</a></li><li><a href="/框架使用/PyTorch/gpu.html" class="active sidebar-link">使用 GPU 加速计算</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/框架使用/PyTorch/gpu.html#概述" class="sidebar-link">概述</a></li><li class="sidebar-sub-header"><a href="/框架使用/PyTorch/gpu.html#常用函数" class="sidebar-link">常用函数</a></li><li class="sidebar-sub-header"><a href="/框架使用/PyTorch/gpu.html#设备" class="sidebar-link">设备</a></li><li class="sidebar-sub-header"><a href="/框架使用/PyTorch/gpu.html#tensor" class="sidebar-link">Tensor</a></li><li class="sidebar-sub-header"><a href="/框架使用/PyTorch/gpu.html#model" class="sidebar-link">Model</a></li><li class="sidebar-sub-header"><a href="/框架使用/PyTorch/gpu.html#单机多-gpu-计算" class="sidebar-link">单机多 GPU 计算</a></li><li class="sidebar-sub-header"><a href="/框架使用/PyTorch/gpu.html#分布式计算" class="sidebar-link">分布式计算</a></li><li class="sidebar-sub-header"><a href="/框架使用/PyTorch/gpu.html#参考" class="sidebar-link">参考</a></li></ul></li><li><a href="/框架使用/PyTorch/model.html" class="sidebar-link">PyTorch 模型</a></li><li><a href="/框架使用/PyTorch/optimizer.html" class="sidebar-link">PyTorch 优化器</a></li><li><a href="/框架使用/PyTorch/tensor.html" class="sidebar-link">PyTorch Tensor</a></li><li><a href="/框架使用/PyTorch/torchvision.html" class="sidebar-link">TorchVision 相关笔记</a></li><li><a href="/框架使用/PyTorch/trick.html" class="sidebar-link">PyTorch 使用技巧</a></li></ul></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>Sci Py</span> <span class="arrow right"></span></p> <!----></section></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>算法总结</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>编程语言</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="使用-gpu-加速计算"><a href="#使用-gpu-加速计算" class="header-anchor">#</a> 使用 GPU 加速计算</h1> <h2 id="概述"><a href="#概述" class="header-anchor">#</a> 概述</h2> <p>默认情况下，PyTorch 中的 GPU 操作是异步的。
当调用一个使用 GPU 的函数时，这些操作会在特定的设备上排队但不一定会在稍后立即执行。</p> <p>使用 <code>nvidia-smi</code> 查看 GPU 使用情况，由于此命令非常常用，建议设置 alias：<code>alias ns=nvidia-smi</code>。</p> <h2 id="常用函数"><a href="#常用函数" class="header-anchor">#</a> 常用函数</h2> <ol><li><code>torch.cuda.is_available()</code>：有无可用的 GPU 设备。</li> <li><code>torch.cuda.device_count()</code>：可用的 GPU 设备数量。</li> <li><code>torch.cuda.current_device()</code>：当前 GPU 设备索引。</li> <li><code>torch.cuda.get_device_name(index)</code>：根据索引查询 GPU 的名字。</li></ol> <h2 id="设备"><a href="#设备" class="header-anchor">#</a> 设备</h2> <ol><li>可与使用字符串，例如：<code>&quot;cuda:1&quot;</code>，<code>cpu</code>。</li> <li>也可以使用 <code>torch.device</code> 对象：
<ol><li>CPU：<code>torch.device('cpu')</code></li> <li>当前 cuda 设备：<code>torch.device('cuda')</code></li> <li>指定 cuda 设备：<code>torch.device('cuda:0')</code></li></ol></li></ol> <h2 id="tensor"><a href="#tensor" class="header-anchor">#</a> Tensor</h2> <p>默认情况下存储在内存中。</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 创建时指定设备</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token comment"># 将 x 复制到第 i 个 GPU 设备上</span>
x <span class="token operator">=</span> x<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>i<span class="token punctuation">)</span>
<span class="token comment"># 查看 x 在哪一个设备上</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
</code></pre></div><p>运算的规则：</p> <ol><li>参与运算的 Tensor 必须在同一个设备上。</li> <li>产生的结果存储在与原 Tensor 相同的设备上。</li></ol> <h2 id="model"><a href="#model" class="header-anchor">#</a> Model</h2> <p>模型也必须先转换到 GPU 上才能使用 GPU 计算。</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 注意这里和 Tensor 的 cuda() 方法有所区别，这里是 in place 的</span>
model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token string">'cuda:1'</span><span class="token punctuation">)</span>
<span class="token comment"># 查看模型在哪一个设备上</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
</code></pre></div><p>输入模型的 Tensor 必须和模型在同一个设备上。</p> <h2 id="单机多-gpu-计算"><a href="#单机多-gpu-计算" class="header-anchor">#</a> 单机多 GPU 计算</h2> <p>使用 torch.nn.DataParallel 将模型包装一下即可：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 默认使用所有 GPU</span>
net <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>DataParallel<span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token comment"># 可以设置只使用指定的 GPU，例如 0 和 3 号 GPU</span>
net <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>DataParallel<span class="token punctuation">(</span>net<span class="token punctuation">,</span> device_ids<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><p>关于模型的保存：<code>DataParallel</code> 实际上也是一个 <code>nn.Module</code>，其中有一个 <code>module</code> 就是我们的实际模型，
保存的时候只保存 <code>net.module</code> 就好：</p> <div class="language-python extra-class"><pre class="language-python"><code>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>module<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;./model.pt&quot;</span><span class="token punctuation">)</span>
new_net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">&quot;./model.pt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
</code></pre></div><p>或者就先给 net 包装一下，再去加载，不推荐这种方式：</p> <div class="language-python extra-class"><pre class="language-python"><code>net <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>DataParallel<span class="token punctuation">(</span>net<span class="token punctuation">)</span>
net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">&quot;./model.pt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="分布式计算"><a href="#分布式计算" class="header-anchor">#</a> 分布式计算</h2> <p><a href="https://pytorch.org/tutorials/intermediate/dist_tuto.html" target="_blank" rel="noopener noreferrer">https://pytorch.org/tutorials/intermediate/dist_tuto.html<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h2 id="参考"><a href="#参考" class="header-anchor">#</a> 参考</h2> <ol><li><a href="https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter04_DL_computation/4.6_use-gpu" target="_blank" rel="noopener noreferrer">https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter04_DL_computation/4.6_use-gpu<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter08_computational-performance/8.2_async-computation" target="_blank" rel="noopener noreferrer">https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter08_computational-performance/8.2_async-computation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter08_computational-performance/8.4_multiple-gpus" target="_blank" rel="noopener noreferrer">https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter08_computational-performance/8.4_multiple-gpus<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ol></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/songquanpeng/cs-notes/edit/main/docs/框架使用/PyTorch/gpu.md" target="_blank" rel="noopener noreferrer">编辑本页面</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">4/9/2021, 11:23:53 AM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/框架使用/PyTorch/data.html" class="prev">
        PyTorch 数据处理
      </a></span> <span class="next"><a href="/框架使用/PyTorch/model.html">
        PyTorch 模型
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.c3f39da1.js" defer></script><script src="/assets/js/2.0d6745a2.js" defer></script><script src="/assets/js/41.853a75bd.js" defer></script>
  </body>
</html>
